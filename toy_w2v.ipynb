{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import itertools as itt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Infinite data iterator\n",
    "def iterData(filename, batch_size, jump_around=False):\n",
    "\n",
    "    # Iterator reading file in batches\n",
    "    def get_batch():\n",
    "    \n",
    "        with open(filename, \"r\") as datfile:\n",
    "\n",
    "            position, offset = 0, batch_size\n",
    "\n",
    "            while True:\n",
    "                \n",
    "                if jump_around:\n",
    "                    offset = np.random.randint(1,4) * batch_size\n",
    "                    \n",
    "                yield datfile.read(batch_size)\n",
    "                position = datfile.seek(position + offset)\n",
    "\n",
    "    batch = get_batch()\n",
    "\n",
    "    # When file is exhausted, start over with new get_batch iterator\n",
    "    while True:\n",
    "        b = next(batch)\n",
    "        if b:\n",
    "            yield  b.split()\n",
    "        else:\n",
    "            print(\"EOF, starting over\")\n",
    "            batch = get_batch()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "EOF, starting over\n",
      "EOF, starting over\n",
      "EOF, starting over\n",
      "EOF, starting over\n",
      "EOF, starting over\n",
      "EOF, starting over\n",
      "EOF, starting over\n",
      "EOF, starting over\n",
      "EOF, starting over\n",
      "['Jelly', 'Warl', 'd! is', 'jell', 'y and', 'smel', 'ly an', \"d it'\", 'll do', 'otool', 'oo!', 'Jelly', 'Warl', 'd! is', 'jell', 'y and', 'smel', 'ly an', \"d it'\", 'll do', 'otool', 'oo!', 'Jelly', 'Warl', 'd! is', 'jell', 'y and', 'smel', 'ly an', \"d it'\", 'll do', 'otool', 'oo!', 'Jelly', 'Warl', 'd! is', 'jell', 'y and', 'smel', 'ly an', \"d it'\", 'll do', 'otool', 'oo!', 'Jelly', 'Warl', 'd! is', 'jell', 'y and', 'smel', 'ly an', \"d it'\", 'll do', 'otool', 'oo!', 'Jelly', 'Warl', 'd! is', 'jell', 'y and', 'smel', 'ly an', \"d it'\", 'll do', 'otool', 'oo!', 'Jelly', 'Warl', 'd! is', 'jell', 'y and', 'smel', 'ly an', \"d it'\", 'll do', 'otool', 'oo!', 'Jelly', 'Warl', 'd! is', 'jell', 'y and', 'smel', 'ly an', \"d it'\", 'll do', 'otool', 'oo!', 'Jelly', 'Warl', 'd! is', 'jell', 'y and', 'smel', 'ly an', \"d it'\", 'll do', 'otool', 'oo!', 'Jelly']\n"
     ]
    }
   ],
   "source": [
    "# Test infinite iterator\n",
    "fn = \"./testf\"\n",
    "\n",
    "with open(fn, \"r\") as tf:\n",
    "    lines = tf.read()\n",
    "print(len(lines))\n",
    "\n",
    "# Only 54 charactors reused indefinitely\n",
    "testIter = iterData(fn, 5)\n",
    "print(list( (\" \".join(next(testIter)) for k in range(100)) ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "## Initialize file iterator\n",
    "from config import settings\n",
    "\n",
    "moreData = iterData(settings[\"data_path\"], 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34993\n",
      "55541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69699\n",
      "83073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93842\n",
      "103080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111692\n",
      "119264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127012\n",
      "135091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142802\n",
      "149803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156643\n",
      "163552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169894\n",
      "177208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183983\n",
      "192246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203599\n",
      "209022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214015\n",
      "219110\n"
     ]
    }
   ],
   "source": [
    "# Construct vocabulary set\n",
    "words = Counter(next(moreData))\n",
    "print(len(words))\n",
    "for k in range(70000):\n",
    "    words.update(next(moreData))\n",
    "    if k % 3000 == 0:\n",
    "        print(len(words))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38918\n"
     ]
    }
   ],
   "source": [
    "# Subsampling with word2vec's subsampling function\n",
    "# following: http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/\n",
    "\n",
    "# Increase the chance of a less common word being kept, and reduce that of very common words\n",
    "def P(word_fraction):\n",
    "\n",
    "    return np.sqrt(1e-7/word_fraction) + 1e-7/word_fraction\n",
    "\n",
    "print(len(words))\n",
    "\n",
    "m = min(words.values())\n",
    "\n",
    "total_words = sum(words.values())\n",
    "\n",
    "words = Counter({ w : int( (count/m)**0.75 )  for w, count in words.most_common() if np.random.uniform() >= P(count/total_words)})\n",
    "\n",
    "print(len(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Word to id mappings\n",
    "word2int = { tup[0] : i for i, tup in enumerate(words.most_common()) }\n",
    "int2word = { i : word for word, i in word2int.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Skip-gram model: for each word, sample a surrounding word within a fixed window (excluding itself),\n",
    "# (Forgot actual terminology) each word is processed in this way k times generating k training targets for it.\n",
    "#\n",
    "\n",
    "def inputsTargets(word_sequence, radius = 4, repeat_num = 2):\n",
    "\n",
    "    words, targets = [None]*len(word_sequence)*repeat_num, [None]*(len)(word_sequence)*repeat_num\n",
    "    batch_size = len(words) # or targets\n",
    "    \n",
    "    for i in range(0,batch_size, repeat_num):\n",
    "        \n",
    "        # Index in word_sequence array ( len(word_sequence) < batch_size )\n",
    "        index = i // repeat_num\n",
    "        word = word_sequence[index]\n",
    "        \n",
    "        lower = 0 if index < radius else index - radius\n",
    "        upper = index + radius\n",
    "        words_in_window = word_sequence[lower:index] + word_sequence[index+1:upper]\n",
    "        \n",
    "        for k in range(repeat_num):\n",
    "            words[i+k] = word\n",
    "            targets[i+k] = words_in_window[np.random.randint(0,len(words_in_window))]\n",
    "\n",
    "    return words, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class littleNN(object):\n",
    "\n",
    "    def __init__(self, word_counts, embedding_dim, neg_sample_size):\n",
    "\n",
    "        ## Vocabulary\n",
    "        self.vocab_size = len(word_counts)\n",
    "        self.unigram_table = list(word_counts.elements()) # immitating original w2v\n",
    "        \n",
    "        ## Network parameters\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.neg_sample_size = neg_sample_size\n",
    "        # layers\n",
    "        self.input2hidden = np.random.uniform( size=(self.vocab_size, embedding_dim ) )\n",
    "        self.hidden2output = np.random.uniform( size=(embedding_dim, self.vocab_size) )\n",
    "        \n",
    "        # sigmoid activation\n",
    "        self.sgmd = lambda x: 1 / ( 1 + np.exp(-x))\n",
    "        \n",
    "    # Softmax\n",
    "    def Softmax(self, w):\n",
    "\n",
    "        # Numerical stability, (avoiding large number overflow)\n",
    "        C = max(w)\n",
    "\n",
    "        expW = np.exp(w-C)\n",
    "        return expW / sum(expW)\n",
    "    \n",
    "    # Negative sampling\n",
    "    def negSample(self):\n",
    "\n",
    "        neg_samples = {}\n",
    "        for k in range(self.neg_sample_size):\n",
    "\n",
    "            # Imitating unigram table idea from original w2v, see;\n",
    "            # http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/\n",
    "            neg_word = self.unigram_table[np.random.randint(len(self.unigram_table))]\n",
    "            \n",
    "            neg_samples[word2int[neg_word]] = 0 # one-hot encoding to 0 \n",
    "\n",
    "        return neg_samples\n",
    "\n",
    "    # Forward pass\n",
    "    def forwardPass(self, inword_id):\n",
    "\n",
    "        # Input to hidden is just a lookup (b/c of one hot word encoding)\n",
    "        i_2_h = self.input2hidden[inword_id]\n",
    "        a = self.sgmd(i_2_h)\n",
    "\n",
    "        # Hidden to output\n",
    "        h_2_o = np.dot(a , self.hidden2output)\n",
    "        softmax_ps = self.Softmax(h_2_o)\n",
    "\n",
    "        return softmax_ps\n",
    "\n",
    "    # Sampled back-prop\n",
    "    def sampledBackProp(self, target_id):\n",
    "        pass\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.24612392e-07 1.33229645e-06 2.37301310e-07 ... 6.44810257e-07\n",
      " 9.78622886e-08 8.14950481e-06]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1675: 0, 0: 0, 2660: 0, 58: 0, 2866: 0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testN = littleNN(words, 300, 5)\n",
    "print(testN.forwardPass(word2int['weather']))\n",
    "testN.negSample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 74,  4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.array([1,2,3,4,5,74,7,78])\n",
    "t[[0,5,3]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "name": "toy_w2v.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
